{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceType":"competition","sourceId":91198,"databundleVersionId":10884264},{"sourceType":"datasetVersion","sourceId":10550636,"datasetId":6412205,"databundleVersionId":10883178}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm torch torchvision albumentations opencv-python pandas scikit-learn matplotlib seaborn tqdm pillow","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:21.050715Z","iopub.execute_input":"2026-02-17T20:34:21.051406Z","iopub.status.idle":"2026-02-17T20:34:26.155397Z","shell.execute_reply.started":"2026-02-17T20:34:21.051378Z","shell.execute_reply":"2026-02-17T20:34:26.154688Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (1.0.20)\nRequirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.23.0+cu126)\nRequirement already satisfied: albumentations in /usr/local/lib/python3.12/dist-packages (2.0.8)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (4.12.0.88)\nRequirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\nRequirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (11.3.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm) (6.0.3)\nRequirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (from timm) (0.36.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from timm) (0.6.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\nRequirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.10.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\nRequirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\nRequirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\nRequirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\nRequirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\nRequirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\nRequirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\nRequirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\nRequirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\nRequirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\nRequirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\nRequirement already satisfied: scipy>=1.10.0 in /usr/local/lib/python3.12/dist-packages (from albumentations) (1.15.3)\nRequirement already satisfied: pydantic>=2.9.2 in /usr/local/lib/python3.12/dist-packages (from albumentations) (2.12.5)\nRequirement already satisfied: albucore==0.0.24 in /usr/local/lib/python3.12/dist-packages (from albumentations) (0.0.24)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.12/dist-packages (from albumentations) (4.12.0.88)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (4.2.1)\nRequirement already satisfied: simsimd>=5.9.2 in /usr/local/lib/python3.12/dist-packages (from albucore==0.0.24->albumentations) (6.5.3)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\nRequirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\nRequirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (26.0rc2)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.9.2->albumentations) (0.4.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (2.32.5)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub->timm) (1.2.1rc0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface_hub->timm) (2026.1.4)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from __future__ import print_function\n\nimport glob\nimport os\nimport random\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:26.157043Z","iopub.execute_input":"2026-02-17T20:34:26.157730Z","iopub.status.idle":"2026-02-17T20:34:35.295270Z","shell.execute_reply.started":"2026-02-17T20:34:26.157688Z","shell.execute_reply":"2026-02-17T20:34:35.294679Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"batch_size = 32\nepochs = 10\nlr = 5e-5\ngamma = 0.7\nseed = 42\n\n\ndef seed_everything(seed):\n    \"\"\"\n    Sets the random seed for reproducibility in python, numpy, and torch.\n    \"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything(seed)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(\"Device used :\", device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.296101Z","iopub.execute_input":"2026-02-17T20:34:35.296535Z","iopub.status.idle":"2026-02-17T20:34:35.568780Z","shell.execute_reply.started":"2026-02-17T20:34:35.296498Z","shell.execute_reply":"2026-02-17T20:34:35.568117Z"}},"outputs":[{"name":"stdout","text":"Device used : cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"DATA_DIR = \"/kaggle/input/ai-vs-human-generated-dataset\"\ntrain_df = pd.read_csv(os.path.join(DATA_DIR, \"train.csv\"))\n\n# Clean data\ntrain_df = train_df.drop(columns=['Unnamed: 0'])  # Drop unnamed column\ntrain_df['label'] = train_df['label'].astype(int)  # Ensure labels are integers\n\ntest_df = pd.read_csv(os.path.join(DATA_DIR, \"test.csv\"))\nif 'Unnamed: 0' in test_df.columns:\n    test_df = test_df.drop(columns=['Unnamed: 0'])\n    \ntest_df['id'] = test_df['id'].apply(lambda x: os.path.join(DATA_DIR, x))\nprint(f\"Train samples: {len(train_df)}\")\nprint(f\"Test samples: {len(test_df)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.570187Z","iopub.execute_input":"2026-02-17T20:34:35.570402Z","iopub.status.idle":"2026-02-17T20:34:35.756395Z","shell.execute_reply.started":"2026-02-17T20:34:35.570383Z","shell.execute_reply":"2026-02-17T20:34:35.755769Z"}},"outputs":[{"name":"stdout","text":"Train samples: 79950\nTest samples: 5540\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import os\n\nprint(\"DATA_DIR:\", DATA_DIR)\nprint(\"\\nDATA_DIR contents:\")\nprint(os.listdir(DATA_DIR))\n\nprint(\"\\nTest DF first ID:\")\nprint(test_df['id'].iloc[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.757276Z","iopub.execute_input":"2026-02-17T20:34:35.757609Z","iopub.status.idle":"2026-02-17T20:34:35.766405Z","shell.execute_reply.started":"2026-02-17T20:34:35.757577Z","shell.execute_reply":"2026-02-17T20:34:35.765785Z"}},"outputs":[{"name":"stdout","text":"DATA_DIR: /kaggle/input/ai-vs-human-generated-dataset\n\nDATA_DIR contents:\n['test_data_v2', 'train.csv', 'test.csv', 'train_data']\n\nTest DF first ID:\n/kaggle/input/ai-vs-human-generated-dataset/test_data_v2/1a2d9fd3e21b4266aea1f66b30aed157.jpg\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = os.path.join(self.img_dir, row['file_name'])\n        image = Image.open(img_path).convert('RGB')\n        label = row['label']\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.767324Z","iopub.execute_input":"2026-02-17T20:34:35.767574Z","iopub.status.idle":"2026-02-17T20:34:35.772772Z","shell.execute_reply.started":"2026-02-17T20:34:35.767553Z","shell.execute_reply":"2026-02-17T20:34:35.771988Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, df, img_dir, transform=None):\n        self.df = df.reset_index(drop=True)\n        self.img_dir = img_dir\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        row = self.df.iloc[idx]\n        img_path = row['id']  # This is already the full path\n        \n        image = Image.open(img_path).convert('RGB')\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        # Return the row index as the ID (0, 1, 2, 3...)\n        return image, idx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.773643Z","iopub.execute_input":"2026-02-17T20:34:35.774292Z","iopub.status.idle":"2026-02-17T20:34:35.786236Z","shell.execute_reply.started":"2026-02-17T20:34:35.774269Z","shell.execute_reply":"2026-02-17T20:34:35.785545Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Check what the test data structure looks like\nimport os\n\nprint(\"Test DF columns:\", test_df.columns.tolist())\nprint(\"First few IDs:\", test_df['id'].head())\nprint(\"\\nDirectory structure:\")\nprint(os.listdir(DATA_DIR))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.786962Z","iopub.execute_input":"2026-02-17T20:34:35.787150Z","iopub.status.idle":"2026-02-17T20:34:35.799970Z","shell.execute_reply.started":"2026-02-17T20:34:35.787131Z","shell.execute_reply":"2026-02-17T20:34:35.799229Z"}},"outputs":[{"name":"stdout","text":"Test DF columns: ['id']\nFirst few IDs: 0    /kaggle/input/ai-vs-human-generated-dataset/te...\n1    /kaggle/input/ai-vs-human-generated-dataset/te...\n2    /kaggle/input/ai-vs-human-generated-dataset/te...\n3    /kaggle/input/ai-vs-human-generated-dataset/te...\n4    /kaggle/input/ai-vs-human-generated-dataset/te...\nName: id, dtype: object\n\nDirectory structure:\n['test_data_v2', 'train.csv', 'test.csv', 'train_data']\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize((255, 255)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(20),\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),  # zoom_range\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.800844Z","iopub.execute_input":"2026-02-17T20:34:35.801116Z","iopub.status.idle":"2026-02-17T20:34:35.810764Z","shell.execute_reply.started":"2026-02-17T20:34:35.801084Z","shell.execute_reply":"2026-02-17T20:34:35.809981Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.812756Z","iopub.execute_input":"2026-02-17T20:34:35.813175Z","iopub.status.idle":"2026-02-17T20:34:35.858379Z","shell.execute_reply.started":"2026-02-17T20:34:35.813153Z","shell.execute_reply":"2026-02-17T20:34:35.857841Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_loader = DataLoader(\n    ImageDataset(train_df, DATA_DIR, train_transform),\n    batch_size=32,\n    shuffle=True,\n    num_workers=2\n)\n\nval_loader = DataLoader(\n    ImageDataset(val_df, DATA_DIR, val_transform),\n    batch_size=32,\n    shuffle=False,\n    num_workers=2\n)\n\n# Use the test_data_v2 subdirectory\ntest_data_dir = os.path.join(DATA_DIR, 'test_data_v2')\n\n# Recreate the test_loader with updated TestDataset\ntest_loader = DataLoader(\n    TestDataset(test_df, DATA_DIR, test_transform),\n    batch_size=batch_size,\n    shuffle=False,  # IMPORTANT: Don't shuffle for test data!\n    num_workers=2,\n    pin_memory=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.859164Z","iopub.execute_input":"2026-02-17T20:34:35.859407Z","iopub.status.idle":"2026-02-17T20:34:35.866125Z","shell.execute_reply.started":"2026-02-17T20:34:35.859383Z","shell.execute_reply":"2026-02-17T20:34:35.865536Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# First, find out where the test images actually are\nimport os\n\n# Check what's in DATA_DIR\nprint(f\"\\n2. Contents of DATA_DIR:\")\ntry:\n    contents = os.listdir(DATA_DIR)\n    for item in contents:\n        print(f\"   - {item}\")\nexcept Exception as e:\n    print(f\"   Error: {e}\")\n\n\npossible_paths = [\n    DATA_DIR,\n    os.path.join(DATA_DIR, 'test_data_v2'),\n    os.path.join(DATA_DIR, 'test'),\n    '/kaggle/input/ai-vs-human-generated-dataset',\n    '/kaggle/input/ai-vs-human-generated-dataset/test_data_v2'\n]\n\nfor path in possible_paths:\n    if os.path.exists(path):\n        try:\n            files = os.listdir(path)\n            if any(f.endswith(('.jpg', '.png', '.jpeg')) for f in files[:10]):\n                print(f\"\\n   ✓ Found images in: {path}\")\n                print(f\"     First 3 files: {files[:3]}\")\n                \n                # Try to construct the path for the first test image\n                first_id = test_df['id'].iloc[0]\n                test_path = os.path.join(path, first_id)\n                print(f\"     Testing path: {test_path}\")\n                print(f\"     Exists: {os.path.exists(test_path)}\")\n                break\n        except Exception as e:\n            print(f\"   ✗ Error checking {path}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:35.866847Z","iopub.execute_input":"2026-02-17T20:34:35.867091Z","iopub.status.idle":"2026-02-17T20:34:36.228950Z","shell.execute_reply.started":"2026-02-17T20:34:35.867060Z","shell.execute_reply":"2026-02-17T20:34:36.228118Z"}},"outputs":[{"name":"stdout","text":"\n2. Contents of DATA_DIR:\n   - test_data_v2\n   - train.csv\n   - test.csv\n   - train_data\n\n   ✓ Found images in: /kaggle/input/ai-vs-human-generated-dataset/test_data_v2\n     First 3 files: ['37a05f4fddf84ac6bd2a9d49446c4c95.jpg', '3e74f0546c5d4b7797aca68370e6ccf0.jpg', '8e2aaa5b998a423e9c90df1c474a5351.jpg']\n     Testing path: /kaggle/input/ai-vs-human-generated-dataset/test_data_v2/1a2d9fd3e21b4266aea1f66b30aed157.jpg\n     Exists: True\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from torchvision import models\n\nmodel = models.efficientnet_b4(weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1)\nnum_ftrs = model.classifier[1].in_features\nmodel.classifier[1] = nn.Linear(num_ftrs, 2)\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:36.230097Z","iopub.execute_input":"2026-02-17T20:34:36.230417Z","iopub.status.idle":"2026-02-17T20:34:37.541725Z","shell.execute_reply.started":"2026-02-17T20:34:36.230383Z","shell.execute_reply":"2026-02-17T20:34:37.540969Z"}},"outputs":[{"name":"stdout","text":"Downloading: \"https://download.pytorch.org/models/efficientnet_b4_rwightman-23ab8bcd.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b4_rwightman-23ab8bcd.pth\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 74.5M/74.5M [00:00<00:00, 168MB/s] \n","output_type":"stream"},{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (features): Sequential(\n    (0): Conv2dNormActivation(\n      (0): Conv2d(3, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n    (1): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48, bias=False)\n            (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(48, 12, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(12, 48, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(24, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 24, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (2): Conv2dNormActivation(\n            (0): Conv2d(24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.00625, mode=row)\n      )\n    )\n    (2): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.018750000000000003, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.03125, mode=row)\n      )\n    )\n    (3): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=192, bias=False)\n            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(192, 8, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(8, 192, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.043750000000000004, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(336, 336, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=336, bias=False)\n            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(56, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.05625, mode=row)\n      )\n    )\n    (4): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(336, 336, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=336, bias=False)\n            (1): BatchNorm2d(336, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(336, 14, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(14, 336, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.06875, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08125, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n      )\n      (5): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.09375, mode=row)\n      )\n    )\n    (5): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.10625000000000001, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.11875000000000001, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n      )\n      (5): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.13125, mode=row)\n      )\n    )\n    (6): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=960, bias=False)\n            (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(960, 40, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(40, 960, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.14375000000000002, mode=row)\n      )\n      (2): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n      )\n      (3): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.15625, mode=row)\n      )\n      (4): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n      )\n      (5): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.16875, mode=row)\n      )\n      (6): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n      )\n      (7): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1632, 1632, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1632, bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(272, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.18125000000000002, mode=row)\n      )\n    )\n    (7): Sequential(\n      (0): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(1632, 1632, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1632, bias=False)\n            (1): BatchNorm2d(1632, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(1632, 68, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(68, 1632, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n      )\n      (1): MBConv(\n        (block): Sequential(\n          (0): Conv2dNormActivation(\n            (0): Conv2d(448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (1): Conv2dNormActivation(\n            (0): Conv2d(2688, 2688, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2688, bias=False)\n            (1): BatchNorm2d(2688, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n            (2): SiLU(inplace=True)\n          )\n          (2): SqueezeExcitation(\n            (avgpool): AdaptiveAvgPool2d(output_size=1)\n            (fc1): Conv2d(2688, 112, kernel_size=(1, 1), stride=(1, 1))\n            (fc2): Conv2d(112, 2688, kernel_size=(1, 1), stride=(1, 1))\n            (activation): SiLU(inplace=True)\n            (scale_activation): Sigmoid()\n          )\n          (3): Conv2dNormActivation(\n            (0): Conv2d(2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n            (1): BatchNorm2d(448, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          )\n        )\n        (stochastic_depth): StochasticDepth(p=0.19375, mode=row)\n      )\n    )\n    (8): Conv2dNormActivation(\n      (0): Conv2d(448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (1): BatchNorm2d(1792, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (2): SiLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=1)\n  (classifier): Sequential(\n    (0): Dropout(p=0.4, inplace=True)\n    (1): Linear(in_features=1792, out_features=2, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"# Define loss, optimizer, and scheduler\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=lr)\nscheduler = StepLR(optimizer, step_size=1, gamma=gamma)\n\ntrain_losses = []\ntrain_accuracies = []\nval_losses = []\nval_accuracies = []\nval_f1s = []","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:37.542718Z","iopub.execute_input":"2026-02-17T20:34:37.542945Z","iopub.status.idle":"2026-02-17T20:34:37.549264Z","shell.execute_reply.started":"2026-02-17T20:34:37.542924Z","shell.execute_reply":"2026-02-17T20:34:37.548547Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"for epoch in range(epochs):\n    model.train()\n    epoch_loss = 0.0\n    epoch_accuracy = 0.0\n\n    for data, label in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\"):\n        data, label = data.to(device), label.to(device)\n\n        optimizer.zero_grad()\n        output = model(data)\n        loss = criterion(output, label)\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n        preds = output.argmax(dim=1)\n        acc = (preds == label).float().mean().item()\n        epoch_accuracy += acc\n\n    epoch_loss /= len(train_loader)\n    epoch_accuracy /= len(train_loader)\n\n    train_losses.append(epoch_loss)\n    train_accuracies.append(epoch_accuracy)\n\n    # -- Validation --\n    model.eval()\n    val_loss = 0.0\n    val_acc = 0.0\n    val_pred_classes = []\n    val_labels_list = []\n\n    with torch.no_grad():\n        for data, label in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\"):\n            data, label = data.to(device), label.to(device)\n            output = model(data)\n\n            loss = criterion(output, label)\n            val_loss += loss.item()\n\n            preds = output.argmax(dim=1)\n            acc = (preds == label).float().mean().item()\n            val_acc += acc\n\n            val_pred_classes.extend(preds.cpu().numpy())\n            val_labels_list.extend(label.cpu().numpy())\n\n    val_loss /= len(val_loader)\n    val_acc /= len(val_loader)\n    \n    val_f1 = f1_score(val_labels_list, val_pred_classes)\n\n    val_losses.append(val_loss)\n    val_accuracies.append(val_acc)\n    val_f1s.append(val_f1)\n\n    print(\n        f\"Epoch [{epoch+1}/{epochs}] \"\n        f\"Train Loss: {epoch_loss:.4f} | Train Acc: {epoch_accuracy:.4f} | \"\n        f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f} | Val F1: {val_f1:.4f}\"\n    )\n\n    scheduler.step()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-17T20:34:37.550406Z","iopub.execute_input":"2026-02-17T20:34:37.550774Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Training Epoch 1:   0%|          | 0/1999 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffb6c6e374fd40a3a901340a435d7efa"}},"metadata":{}}],"execution_count":null},{"cell_type":"code","source":"torch.save(model.state_dict(), \"model_weights.pth\")\n\ntorch.save(model, \"model.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.title(\"Training and Validation Loss\")\nplt.plot(train_losses, label=\"Training\")\nplt.plot(val_losses, label=\"Validation\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Loss\")\nplt.legend()\nplt.show()\n\nplt.figure(figsize=(10,5))\nplt.title(\"Training and Validation Accuracy\")\nplt.plot(train_accuracies, label=\"Training\")\nplt.plot(val_accuracies, label=\"Validation\")\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\npredictions = []\nimage_names = []\n\nwith torch.no_grad():\n    for data, names in tqdm(test_loader, desc=\"Predicting\"):\n        data = data.to(device)\n        outputs = model(data)\n        \n        # On récupère la classe prédite\n        preds = outputs.argmax(dim=1)  # shape [batch_size]\n        \n        predictions.extend(preds.cpu().numpy())\n        image_names.extend([f\"test_data/{name}\" for name in names])\n\n# Créer le DataFrame au format \"id,label\"\nsubmission_df = pd.DataFrame({\n    'id': image_names,\n    'label': predictions\n})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n\nprint(\"\\n Submission file created at: /kaggle/working/submission.csv\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}